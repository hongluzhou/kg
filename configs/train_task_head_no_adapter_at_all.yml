# -- Project settings:
exp_name: baseline
notes: Baseline | No Adapter
project: ginst
entity: hongluzhou


# -- External knowledge settings:
need_external_knowledge: False

 
# -- Downstream settings:
downstream_dataset_name: COIN
# {CrossTask | COIN}
downstream_task_name: step_forecasting
# { task_cls | step_forecasting }


# CrossTask paths
cross_task_video_dir: /export/einstein-vision/multimodal_video/datasets/CrossTask/videos
cross_task_s3d_feat_dir: /export/home/data/crosstask/feats

# COIN paths
coin_video_dir: /export/einstein-vision/multimodal_video/datasets/COIN/videos
coin_annoataion_json: /export/einstein-vision/multimodal_video/datasets/COIN/annotations/COIN.json
coin_s3d_feat_dir: /export/home/data/coin/feats
coin_step_forecasting_history: 1


# -- Model settings:
# ---- Video pretrained model:
model_video_pretrained_dim: 512

# ---- Task head task_cls
model_task_cls_head_name: transformer_one_layer
# { transformer_one_layer | }
# --------- Task head task_cls trasformer configurations
model_task_cls_tx_hidden_dim: 512
model_task_cls_tx_nhead: 8
model_task_cls_tx_dim_feedforward: 1024
model_task_cls_tx_dropout: 0
model_task_cls_tx_activation: relu
model_task_cls_tx_time_pos_embed_type: absolute_learned_1D
model_task_cls_tx_max_time_ids_embed: 500
model_task_cls_classifier_hidden_dim: 128
model_task_cls_num_classes: 83
# cross task - task recognition: 83
# coin - task recognition: 180


# ---- Task head step_forecasting
model_step_forecasting_head_name: transformer_one_layer
# { transformer_one_layer | }
# --------- Task head step_forecasting trasformer configurations
model_step_forecasting_tx_hidden_dim: 512
model_step_forecasting_tx_nhead: 8
model_step_forecasting_tx_dim_feedforward: 1024
model_step_forecasting_tx_dropout: 0
model_step_forecasting_tx_activation: relu
model_step_forecasting_tx_time_pos_embed_type: absolute_learned_1D
model_step_forecasting_tx_max_time_ids_embed: 500
model_step_forecasting_classifier_hidden_dim: 768
model_step_forecasting_num_classes: 778
# coin - step forecasting: 778


# ---- Task head training settings
task_head_batch_size: 16
task_head_num_epochs: 1000
# 2
task_head_early_stop_patience: 50
task_head_batch_train_log_freq: 1
# 50, a sufficiently large number means no log at all
task_head_batch_test_log_freq: 1
# 20, a sufficiently large number means no log at all
task_head_optimizer: 'adam'
task_head_learning_rate: 0.0001
task_head_weight_decay: 0.001
task_head_lr_warm_up: False
task_head_warmup_steps: 5000


# -- General settings:
seed: -1
# seed is -1 means random, otherwise put a seed number that is greater than 0
cudnn_benchmark: True


# -- Runtime settings:
num_workers: -1
# num_workers -1 will dynamically compute the number of available workers
device: cuda
  
# -- Output settings:
checkpoint_dir: /export/home/outputs/ginst/output_checkpoints/train_task_head_no_adatper_at_all/
log_dir: /export/home/outputs/ginst/output_logs/
# checkpoint_dir: ./output_checkpoints/train_task_head_no_adatper_at_all
# log_dir: ./output_logs/


